# ğŸ¤ ASR Model Evaluation & Benchmarking

This project evaluates **automatic speech recognition (ASR) models** (e.g., Whisper) on multiple datasets, including **Common Voice**, **KathBath**, and **IndicTTS**.

## ğŸš€ Features
- âœ… **Supports Whisper & other ASR models**  
- âœ… **Benchmark on real-world datasets**  
- âœ… **Evaluate WER (Word Error Rate), CER (Character Error Rate)**  
- âœ… **Supports streaming & VAD (Voice Activity Detection)**  
- âœ… **Runs on local machine, remote servers, or Google Colab**  

---

## ğŸ“‚ Project Structure
```
/asr_models/                   # Project root
â”‚â”€â”€ /models/                   # ASR model implementations
â”‚   â”œâ”€â”€ __init__.py            
â”‚   â”œâ”€â”€ whisper_model.py       # Whisper ASR model
â”‚â”€â”€ /evaluations/              # Evaluation scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluator.py           # Evaluates ASR models
â”‚â”€â”€ /results/                  # Stores benchmark results
â”‚â”€â”€ /datasets/                 # Custom datasets (if needed)
â”‚â”€â”€ settings.py                # Configuration (paths, tokens, etc.)
â”‚â”€â”€ run_colab.ipynb            # Colab setup
â”‚â”€â”€ requirements.txt           # Dependencies
â”‚â”€â”€ README.md                  # This file
â”‚â”€â”€ main.py                    # Main execution file
```

---

## ğŸ’¾ Installation

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/YOUR_GITHUB/asr_models.git
cd asr_models
```

### **2ï¸âƒ£ Set Up a Virtual Environment**
```bash
python3 -m venv venv
source venv/bin/activate
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

---

## ğŸ”§ Configuration

### **ğŸ”‘ Hugging Face Token (For Common Voice 17.0)**
1. Get your **Hugging Face access token** from:  
   [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
2. Add it as an environment variable:  
   ```bash
   export HUGGINGFACE_TOKEN="your_token_here"
   ```
3. Or save it in `settings.py`:
   ```python
   import os
   class Settings:
       HF_TOKEN = "your_token_here"
   ```

---

## ğŸ¯ Running the ASR Evaluation

### **ğŸ“ Evaluate ASR Models**
Run:
```bash
python evaluations/evaluator.py --num_samples 50 --vad --streaming
```

**CLI Arguments:**
| Argument | Description | Example |
|----------|------------|---------|
| `--num_samples` | Number of test samples per dataset | `--num_samples 100` |
| `--vad` | Enable voice activity detection | `--vad` |
| `--streaming` | Enable streaming transcription | `--streaming` |

---

## ğŸ“Š Viewing Results

Results are saved in `/results/`:
```
results/
â”œâ”€â”€ common_voice_20250129_140000.csv
â”œâ”€â”€ kathbath_20250129_140000.csv
â”œâ”€â”€ indictts_20250129_140000.csv
â”œâ”€â”€ summary_results_20250129_140000.csv
```

| Model | Dataset | WER | CER | VAD | Streaming | Reference | Prediction |
|--------|---------|------|------|------|-----------|------------|-------------|
<!-- | Whisper | Common Voice | 8.2% | 4.5% | âœ… | âœ… | "à¤¸à¥à¤ªà¥à¤°à¤­à¤¾à¤¤" | "à¤¸à¥à¤ªà¥à¤°à¤­à¤¾à¤¤" | -->

---

## ğŸ”‹ Running on Google Colab

1. Open **Google Colab**
2. Run:
   ```bash
   !git clone "https://github.com/YOUR_GITHUB/asr_models.git"
   %cd asr_models
   !pip install -r requirements.txt
   ```
3. Authenticate Hugging Face:
   ```bash
   from huggingface_hub import notebook_login
   notebook_login()
   ```
4. Run:
   ```bash
   !python evaluations/evaluator.py --num_samples 50 --vad --streaming
   ```

---

## ğŸ› ï¸ Troubleshooting

### **1ï¸âƒ£ `OSError: PortAudio library not found` (Google Colab)**
Run:
```bash
!apt-get install -y portaudio19-dev
!pip install sounddevice
```
Then restart the runtime:
```python
import os
os._exit(00)
```

---

### **2ï¸âƒ£ `DatasetNotFoundError: Dataset is gated`**
Authenticate Hugging Face:
```bash
huggingface-cli login
```
Or pass the token:
```python
dataset = load_dataset("mozilla-foundation/common_voice_17_0", "hi", split="test", use_auth_token=hf_token)
```

---

### **3ï¸âƒ£ `RuntimeError: expected scalar type Float but found Half`**
Your **Whisper model is in `float16`**, but input is `float32`. Fix by converting input:
```python
if self.compute_type == "float16" and self.device == "cuda":
    audio = torch.tensor(audio, dtype=torch.float16, device=self.device)
else:
    audio = torch.tensor(audio, dtype=torch.float32, device=self.device)
```

---

## ğŸ’ª Future Improvements
- ğŸ”¹ Support for **multiple ASR models** beyond Whisper.
- ğŸ”¹ Add **parallel processing for faster evaluations**.
- ğŸ”¹ Improve **speaker diarization support**.

---

## ğŸ“„ Contact
For issues or contributions, create a pull request or open an issue on GitHub.

---